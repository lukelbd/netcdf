{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208277e3",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851ce6f",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318c83a",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "Earth scientists work with huge, 4+ dimensional datasets (3\n",
    "spatial dimensions, 1 time dimension, and sometimes even more).\n",
    "\n",
    "-   Example: Air temperature (longitude, latitude, height, time)\n",
    "\n",
    "-   Example: Surface pressure from \"ensemble\" of model simulations\n",
    "    (longitude, latitude, time, ensemble member)\n",
    "\n",
    "-   Example: Satellite-retrieved radiation (projection x-coordinate,\n",
    "    projection y-coordinate, wavenumber)\n",
    "    \n",
    "### Question\n",
    "\n",
    "What's the best way to **store** these 4+ dimensional datasets?\n",
    "\n",
    "-   Spreadsheets? Not enough dimensions.\n",
    "\n",
    "-   Matrices? No way to annotate \"rows\", \"columns\", etc.\n",
    "\n",
    "### Answer\n",
    "\n",
    "The [NetCDF](https://en.wikipedia.org/wiki/NetCDF) format\n",
    "(Network Common Data Form) developed by\n",
    "[UCAR/Unidata](https://www.unidata.ucar.edu/software/netcdf/) (right\n",
    "down the road!).\n",
    "\n",
    "-   Description: Annotated N-dimensional matrices (arrays)\n",
    "\n",
    "-   File extension: `.nc`\n",
    "\n",
    "There are other similar data formats\n",
    "([HDF](https://en.wikipedia.org/wiki/Hierarchical_Data_Format),\n",
    "[GRIB](https://en.wikipedia.org/wiki/GRIB)), and some software can work\n",
    "seamlessly with different formats... but **NetCDF is your new best friend**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9d0fb",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b409669",
   "metadata": {},
   "source": [
    "NetCDF files have the following features:\n",
    "\n",
    "-   Global attributes, describing the contents of the NetCDF file. **Attributes are optional.**\n",
    "\n",
    "-   Named dimensions, describing the dimensions on the arrays contained in the NetCDF file.\n",
    "\n",
    "-   Named variables, i.e. the data arrays, each with their own dimensions and attributes.\n",
    "\n",
    "- \"Coordinate variables\", named variables whose name matches a dimension name. **Coordinate variables are optional.**\n",
    "\n",
    "Example: A simple file containing [HadCRUT](https://crudata.uea.ac.uk/cru/data/temperature/) land and sea surface temperature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0437f2a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf sst {\n",
      "dimensions:\n",
      "\tlatitude = 36 ;\n",
      "\tlongitude = 72 ;\n",
      "\tfield_status_string_length = 1 ;\n",
      "\ttime = UNLIMITED ; // (2010 currently)\n",
      "variables:\n",
      "\tfloat latitude(latitude) ;\n",
      "\t\tlatitude:standard_name = \"latitude\" ;\n",
      "\t\tlatitude:long_name = \"latitude\" ;\n",
      "\t\tlatitude:point_spacing = \"even\" ;\n",
      "\t\tlatitude:units = \"degrees_north\" ;\n",
      "\t\tlatitude:axis = \"Y\" ;\n",
      "\tfloat longitude(longitude) ;\n",
      "\t\tlongitude:standard_name = \"longitude\" ;\n",
      "\t\tlongitude:long_name = \"longitude\" ;\n",
      "\t\tlongitude:point_spacing = \"even\" ;\n",
      "\t\tlongitude:units = \"degrees_east\" ;\n",
      "\t\tlongitude:axis = \"X\" ;\n",
      "\tfloat time(time) ;\n",
      "\t\ttime:standard_name = \"time\" ;\n",
      "\t\ttime:long_name = \"time\" ;\n",
      "\t\ttime:units = \"days since 1850-1-1 00:00:00\" ;\n",
      "\t\ttime:calendar = \"gregorian\" ;\n",
      "\t\ttime:start_year = 1850s ;\n",
      "\t\ttime:end_year = 2017s ;\n",
      "\t\ttime:start_month = 1s ;\n",
      "\t\ttime:end_month = 6s ;\n",
      "\t\ttime:axis = \"T\" ;\n",
      "\tfloat temperature_anomaly(time, latitude, longitude) ;\n",
      "\t\ttemperature_anomaly:long_name = \"near_surface_temperature_anomaly\" ;\n",
      "\t\ttemperature_anomaly:units = \"K\" ;\n",
      "\t\ttemperature_anomaly:missing_value = -1.e+30f ;\n",
      "\t\ttemperature_anomaly:_FillValue = -1.e+30f ;\n",
      "\t\ttemperature_anomaly:reference_period = 1961s, 1990s ;\n",
      "\tchar field_status(time, field_status_string_length) ;\n",
      "\t\tfield_status:long_name = \"field_status\" ;\n",
      "\n",
      "// global attributes:\n",
      "\t\t:title = \"HadCRUT4 near-surface temperature ensemble data - ensemble median\" ;\n",
      "\t\t:institution = \"Met Office Hadley Centre / Climatic Research Unit, University of East Anglia\" ;\n",
      "\t\t:history = \"Updated at 26/07/2017 12:27:42\" ;\n",
      "\t\t:source = \"CRUTEM.4.5.0.0, HadSST.3.1.1.0\" ;\n",
      "\t\t:comment = \"\" ;\n",
      "\t\t:reference = \"Morice, C. P., J. J. Kennedy, N. A. Rayner, and P. D. Jones (2012), Quantifying uncertainties in global and regional temperature change using an ensemble of observational estimates: The HadCRUT4 dataset, J. Geophys. Res., doi:10.1029/2011JD017187\" ;\n",
      "\t\t:version = \"HadCRUT.4.5.0.0\" ;\n",
      "\t\t:Conventions = \"CF-1.0\" ;\n",
      "\t\t:ensemble_members = 100s ;\n",
      "\t\t:ensemble_member_index = 0s ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ncdump -h data/sst.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3b00b",
   "metadata": {},
   "source": [
    "NetCDF file formats also have [different \"version\n",
    "numbers\"](https://www.unidata.ucar.edu/software/netcdf/docs/faq.html#How-many-netCDF-formats-are-there-and-what-are-the-differences-among-them):\n",
    "\n",
    "\n",
    "-   NetCDF3 (version 3) [retired in\n",
    "    2008](https://www.unidata.ucar.edu/software/netcdf/docs/RELEASE_NOTES.html#autotoc_md60).\n",
    "    Unidata is [currently version\n",
    "    4](https://www.unidata.ucar.edu/software/netcdf/docs/RELEASE_NOTES.html#autotoc_md0).\n",
    "\n",
    "-   However version 3 still widespread (scientists are slow to change\n",
    "    their ways... too many other things to worry about).\n",
    "\n",
    "-   Some things in NetCDF4 are impossible in NetCDF3 (e.g., multiple unlimited\n",
    "    dimensions).\n",
    "\n",
    "-   Weird read/write bugs are sometimes due to version\n",
    "    incompatibilities.\n",
    "\n",
    "NetCDF3 is still everywhere, so you may need to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2034ba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netCDF-4\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ncdump -k data/sst.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6be5d93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classic\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ncdump -k data/landfracs.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06354d07",
   "metadata": {},
   "source": [
    "# Command-line tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8d275",
   "metadata": {},
   "source": [
    "There's lots of software for working with NetCDF (HDF, GRIB) files.\n",
    "First, the command-line tools:\n",
    "\n",
    "- [NCO](http://nco.sourceforge.net/nco.html) (NetCDF Operators).\n",
    "- [CDO](https://code.mpimet.mpg.de/projects/cdo/wiki/Cdo#Documentation) (Climate Data Operators)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f3309",
   "metadata": {},
   "source": [
    "## NCO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da56fdc",
   "metadata": {},
   "source": [
    "- Developed by Unidata, the makers of the NetCDF format.\n",
    "- Extremely versatile but a bit clunky to learn.\n",
    "- Tend to be slower.\n",
    "\n",
    "\n",
    "These consist of a suite of separate commands:\n",
    "\n",
    "- ncap2: netCDF Arithmetic Processor (examples)\n",
    "- ncatted: netCDF ATTribute EDitor (examples)\n",
    "- ncbo: netCDF Binary Operator (addition, multiplication...) (examples)\n",
    "- ncclimo: netCDF CLIMatOlogy Generator (examples)\n",
    "- nces: netCDF Ensemble Statistics (examples)\n",
    "- ncecat: netCDF Ensemble conCATenator (examples)\n",
    "- ncflint: netCDF FiLe INTerpolator (examples)\n",
    "- ncks: netCDF Kitchen Sink (examples)\n",
    "- ncpdq: netCDF Permute Dimensions Quickly, Pack Data Quietly (examples)\n",
    "- ncra: netCDF Record Averager (examples)\n",
    "- ncrcat: netCDF Record conCATenator (examples)\n",
    "- ncremap: netCDF REMAPer (examples)\n",
    "- ncrename: netCDF RENAMEer (examples)\n",
    "- ncwa: netCDF Weighted Averager (examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8bf8f1",
   "metadata": {},
   "source": [
    "## CDO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370798c1",
   "metadata": {},
   "source": [
    "- Developed by the Max Planck Institute for Meteorology.\n",
    "- Sleeker and more \"modern\" NetCDf tool.\n",
    "- Consists of a single command-line command `cdo` but with [hundreds of subcommands](https://code.mpimet.mpg.de/projects/cdo/wiki/Tutorial#Basic-Usage).\n",
    "- Inclues a game-changer \"[operator chaining](https://code.mpimet.mpg.de/projects/cdo/embedded/index.html#x1-120001.2.6)\" feature.\n",
    "- Powered by C++ with built-in parallelization, so this tends to be faster\n",
    "- The only major caveat: Your data must fit a rigid format, with 2 horizontal dimensions, an optional vertical dimension, and an optional time dimension.\n",
    "- CDO must be able to infer these dimensions based on the attributes (using the [CF-standards for coordinates](http://cfconventions.org/cf-conventions/cf-conventions.html#coordinate-types)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474e96d",
   "metadata": {},
   "source": [
    "Here's a quick survey of CDO's subcommands, with examples:\n",
    "\n",
    "Regrid from one arbitrary grid (e.g. rotated pole, hexagonal cells) to another (you can choose from a suite of algorithms).\n",
    "\n",
    "```\n",
    "cdo remapcon,destination_grid.txt in.nc out.nc\n",
    "```\n",
    "\n",
    "Interpolate to different vertical; levels:\n",
    "\n",
    "```\n",
    "cdo intlevel,1000,900,800,700,600,500,400,300,200 in.nc out.nc\n",
    "```\n",
    "\n",
    "Linear least-squares trendline, ignoring missing values:\n",
    "\n",
    "```\n",
    "cdo regres -seldate,1980-01-01T00:00:00,2009-12-31T23:59:59 in.nc out.nc\n",
    "```\n",
    "\n",
    "Monthly daily and seasonal statistics:\n",
    "\n",
    "```\n",
    "cdo ymonmean in.nc climate.nc\n",
    "```\n",
    "\n",
    "Spatial operations:\n",
    "\n",
    "```\n",
    "cdo zonmean in.nc out.nc  # zonal average\n",
    "cdo fldmean in .nc out.nc  # global average\n",
    "cdo mulc,101325 -vertmean -genlevelbounds  # vertical integral\n",
    "```\n",
    "\n",
    "Spatial empirical orthogonal functions\n",
    "\n",
    "```\n",
    "cdo eof,10 file.nc evals.nc evecs.nc\n",
    "```\n",
    "\n",
    "Summary statistics for your file:\n",
    "\n",
    "```\n",
    "cdo infon -selname,t -seltimestep,1 file.nc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf607aa",
   "metadata": {},
   "source": [
    "# Python tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7066f9",
   "metadata": {},
   "source": [
    "Next, the python tools:\n",
    "\n",
    "-   [netCDF4](https://unidata.github.io/netcdf4-python/)\n",
    "\n",
    "-   [xarray](http://xarray.pydata.org/en/stable/)\n",
    "\n",
    "-   [iris\n",
    "    \"cubes\"](https://scitools.org.uk/iris/docs/v1.13.0/userguide/loading_iris_cubes.html) -- this tool is older, less widely used, falling out of favor (xarray was built\n",
    "    as an [improvement on\n",
    "    \"cubes\"](http://xarray.pydata.org/en/stable/getting-started-guide/faq.html#what-other-netcdf-related-python-libraries-should-i-know-about)).\n",
    "    \n",
    "-   [cf-python](https://github.com/NCAS-CMS/cf-python) -- this tool is not widely used.\n",
    "\n",
    "We will focus on the two most widely used tools, netCDF4 and xarray."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441bfd7",
   "metadata": {},
   "source": [
    "## netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd387c",
   "metadata": {},
   "source": [
    "- The more \"low-level\" tool (requires more lines of code).\n",
    "- Generally the fastest tool (unless you are using dask on a supercomputer -- see below).\n",
    "- Used *internally* in the xarray source code.\n",
    "- **Warning**: Confusingly, \"netCDF4\" works with both NetCDF versions 3 and 4! \n",
    "\n",
    "I recommend using netCDF4 only if you have a very specific reason to use it over xarray (e.g., running calculations on many many small files on a laptop or individual server).\n",
    "\n",
    "The following example reads XYZT temperature and wind data, then saves YZT \"eddy heat\n",
    "flux\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0252781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import netCDF4 as nc4\n",
    "\n",
    "filename = sys.argv[1]\n",
    "get_dict = lambda obj: {key: val for key, val in obj.__dict__.items() if key[:1] != '_'}\n",
    "with nc4.Dataset(filename, 'r') as f:\n",
    "    # Get dimensions\n",
    "    time_var = f['time']\n",
    "    plev_var = f['plev']\n",
    "    lon_var = f['lon']\n",
    "    lat_var = f['lat']\n",
    "    time = time_var[:]\n",
    "    plev = plev_var[:]\n",
    "    lon = lon_var[:]\n",
    "    lat = lat_var[:]\n",
    "\n",
    "    # Get data\n",
    "    u_var = f['u']\n",
    "    v_var = f['v']\n",
    "    t_var = f['t']\n",
    "    u = u_var[:]\n",
    "    v = v_var[:]\n",
    "    t = t_var[:]\n",
    "\n",
    "    # Get attributes\n",
    "    time_att = get_dict(time_var)\n",
    "    plev_att = get_dict(plev_var)\n",
    "    lat_att = get_dict(lat_var)\n",
    "\n",
    "# Perform calculations\n",
    "emf = (\n",
    "    (u - u.mean(axis=-1, keepdims=True)) * (v - v.mean(axis=-1, keepdims=True))\n",
    ").mean(axis=-1)\n",
    "ehf = (\n",
    "    (t - t.mean(axis=-1, keepdims=True)) * (v - v.mean(axis=-1, keepdims=True))\n",
    ").mean(axis=-1)\n",
    "\n",
    "# Save file\n",
    "outname = 'out/netcdf4.nc'\n",
    "if os.path.exists(outname):\n",
    "    os.remove(outname)\n",
    "with nc4.Dataset(outname, 'w') as f:\n",
    "    # Make dimensions\n",
    "    # NOTE: This is very similar syntax to low-level C and Fortran libs\n",
    "    f.createDimension('time', None)\n",
    "    f.createDimension('plev', plev.size)\n",
    "    f.createDimension('lat', lat.size)\n",
    "\n",
    "    # Make new variables\n",
    "    time_var = f.createVariable('time', 'f8', ('time',))\n",
    "    plev_var = f.createVariable('plev', 'f8', ('plev',))\n",
    "    lat_var = f.createVariable('lat', 'f8', ('lat',))\n",
    "    ehf_var = f.createVariable('ehf', 'f8', ('time', 'plev', 'lat',))\n",
    "    emf_var = f.createVariable('emf', 'f8', ('time', 'plev', 'lat',))\n",
    "\n",
    "    # Add attributes\n",
    "    # WARNING: Updating __dict__ silently fails for some reason!\n",
    "    for var, dict_ in ((time_var, time_att), (plev_var, plev_att), (lat_var, lat_att)):\n",
    "        for key, value in dict_.items():\n",
    "            setattr(var, key, value)\n",
    "    for var, dict_ in (\n",
    "        (emf_var, {'long_name': 'eddy momentum flux', 'units': 'm**2/s**2'}),\n",
    "        (ehf_var, {'long_name': 'eddy heat flux', 'units': 'K*m/s'}),\n",
    "    ):\n",
    "        for key, value in dict_.items():\n",
    "            setattr(var, key, value)\n",
    "\n",
    "    # Write to vars\n",
    "    time_var[:] = time\n",
    "    plev_var[:] = plev\n",
    "    lat_var[:] = lat\n",
    "    ehf_var[:] = ehf\n",
    "    emf_var[:] = emf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9be72",
   "metadata": {},
   "source": [
    "## xarray "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c2902",
   "metadata": {},
   "source": [
    "* The more \"high-level\" tool (requires fewer lines of code).\n",
    "* The \"new kid\" on the block but *extremely* powerful.\n",
    "* Generally slower, unless you are using a supercomputer and combine xarray with [dask-powered parallel computing](http://xarray.pydata.org/en/stable/user-guide/dask.html).\n",
    "\n",
    "I recommend using xarray most of the time.\n",
    "\n",
    "The following example does the same as the above netCDF4 example (note much less code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c056916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "filename = sys.argv[1]\n",
    "nt = int(sys.argv[2])  # number of time chunks; 0 to disable chunking\n",
    "if nt:  # 1 chunk per level\n",
    "    # Chunk each 3D slice separately. So make max chunk size along other dims big.\n",
    "    N = 100000  # max chunk size for lon/lat dimensions\n",
    "    chunks = {\n",
    "        'time': nt,\n",
    "        'plev': N,\n",
    "        'lat': N,\n",
    "        'lon': N,\n",
    "    }  # one chunk per horizontal slice, works pretty well\n",
    "    data = xr.open_dataset(filename, chunks=chunks, decode_times=False)\n",
    "else:\n",
    "    data = xr.open_dataset(filename, decode_times=False)\n",
    "\n",
    "# Next perform calculations\n",
    "emf = ((data.u - data.u.mean('lon')) * (data.v - data.v.mean('lon'))).mean('lon')\n",
    "ehf = ((data.t - data.t.mean('lon')) * (data.v - data.v.mean('lon'))).mean('lon')\n",
    "emf.name = 'emf'\n",
    "ehf.name = 'ehf'\n",
    "emf.attrs = {'long_name': 'eddy momentum flux', 'units': 'm**2/s**2'}\n",
    "ehf.attrs = {'long_name': 'eddy heat flux', 'units': 'K*m/s'}\n",
    "\n",
    "# Save file\n",
    "out = xr.Dataset({'emf': emf, 'ehf': ehf})\n",
    "outname = f'out/xarray_{nt}.nc'\n",
    "if os.path.exists(outname):\n",
    "    os.remove(outname)\n",
    "out.to_netcdf(outname, mode='w')  # specify whether we did chunking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07f0e7",
   "metadata": {},
   "source": [
    "# Other tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c6ac15",
   "metadata": {},
   "source": [
    "## MATLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a7ceb",
   "metadata": {},
   "source": [
    "If possible, I recommend against using [MATLAB](https://www.mathworks.com/products/matlab.html).\n",
    "\n",
    "MATLAB's syntax is convenient, but python has many useful tools that have no MATLAB equivalent (e.g., dask, xarray, jupyter, metpy). Python is also open source and has a massive community, which helps with debugging code and developing even more useful tools.\n",
    "\n",
    "If you know MATLAB but don't know python, an REU internship is a great time to learn (that's how I did it!).\n",
    "\n",
    "If you really need to use MATLAB (for example, you will be working from MATLAB scripts provided by your advisor), more information on MATLAB's NetCDF utilities can be found [here](https://www.mathworks.com/help/matlab/network-common-data-form.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a7a39",
   "metadata": {},
   "source": [
    "## Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8d14d",
   "metadata": {},
   "source": [
    "If possible, I also recommend against the [Julia language](https://julialang.org/) for the time being.\n",
    "\n",
    "Julia's NetCDF tools are currently not as advanced as python, and the community is relatively small. The Julia language is a really awesome idea, and I'm excited about it! But I don't think Julia has proved itself as being worthy for us to jump ship from python yet.\n",
    "\n",
    "If you disagree, the two major NetCDF-processing tools in Julia are [NetCDF.jl](https://github.com/JuliaGeo/NetCDF.jl) (for MATLAB-style syntax) and [NCDatasets.jl](https://github.com/Alexander-Barth/NCDatasets.jl) (for python's xarray-style syntax)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a5bfe",
   "metadata": {},
   "source": [
    "## NCL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed767d",
   "metadata": {},
   "source": [
    "A final tool I didn't mention is [NCL](https://www.ncl.ucar.edu) (the NCAR Command\n",
    "Language). This is one of my favorites!\n",
    "\n",
    "-   MATLAB: Everything is an array.\n",
    "\n",
    "-   Python: Everything is an object (or dictionary, depending on who you\n",
    "    ask).\n",
    "\n",
    "-   NCL: Everything is a NetCDF-formatted dataset. If you're a\n",
    "    geoscientist, this paradigm is pretty awesome.\n",
    "\n",
    "Sadly, in 2021 you should **avoid using NCL** for two reasons:\n",
    "\n",
    "-   NCL [is being\n",
    "    deprecated](https://www.ncl.ucar.edu/Document/Pivot_to_Python/september_2019_update.shtml)\n",
    "    (Unidata developers are now focusing on python tools).\n",
    "\n",
    "-   As \"cool\" as NCL is, it is very slow... among the slowest tools (see [these\n",
    "    benchmark results](https://github.com/lukelbd/atmos-benchmarks)).\n",
    "    \n",
    "In case you do need to use it, the following example reads XYZT temperature and wind data, then saves YZT \"eddy heat\n",
    "flux\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a23f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf fluxes_input {\n",
      "dimensions:\n",
      "\ttime = UNLIMITED ; // (200 currently)\n",
      "\tplev = 60 ;\n",
      "\tlat = 18 ;\n",
      "\tlon = 36 ;\n",
      "variables:\n",
      "\tfloat time(time) ;\n",
      "\t\ttime:long_name = \"time\" ;\n",
      "\t\ttime:calendar = \"360_day\" ;\n",
      "\t\ttime:units = \"days since 00-01-01 00:00:00\" ;\n",
      "\t\ttime:axis = \"T\" ;\n",
      "\t\ttime:standard_name = \"time\" ;\n",
      "\tfloat plev(plev) ;\n",
      "\t\tplev:long_name = \"pressure level\" ;\n",
      "\t\tplev:units = \"hPa\" ;\n",
      "\t\tplev:axis = \"Z\" ;\n",
      "\t\tplev:standard_name = \"pressure level\" ;\n",
      "\tfloat lat(lat) ;\n",
      "\t\tlat:long_name = \"latitude\" ;\n",
      "\t\tlat:units = \"degN\" ;\n",
      "\t\tlat:axis = \"Y\" ;\n",
      "\t\tlat:standard_name = \"latitude\" ;\n",
      "\tfloat lon(lon) ;\n",
      "\t\tlon:long_name = \"longitude\" ;\n",
      "\t\tlon:units = \"degE\" ;\n",
      "\t\tlon:axis = \"X\" ;\n",
      "\t\tlon:standard_name = \"longitude\" ;\n",
      "\tdouble u(time, plev, lat, lon) ;\n",
      "\t\tu:long_name = \"zonal wind\" ;\n",
      "\t\tu:units = \"m/s\" ;\n",
      "\tdouble v(time, plev, lat, lon) ;\n",
      "\t\tv:long_name = \"meridional wind\" ;\n",
      "\t\tv:units = \"m/s\" ;\n",
      "\tdouble t(time, plev, lat, lon) ;\n",
      "\t\tt:long_name = \"temperature\" ;\n",
      "\t\tt:units = \"K\" ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ncdump -h data/fluxes_input.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545fa0f8",
   "metadata": {},
   "source": [
    "The `fluxes.ncl` script contains the following:\n",
    "\n",
    "```\n",
    "; Sample NCL file\n",
    "; This is a comment\n",
    "f = addfile(\"data/fluxes_input.nc\", \"r\")\n",
    "o = addfile(\"data/fluxes_output.nc\", \"c\")\n",
    "t = f->t\n",
    "v = f->v\n",
    "tstar = t - conform(t, dim_avg_n(t, 3), (/0, 1, 2/))  ; zonal temperature anomaly\n",
    "vstar = v - conform(v, dim_avg_n(v, 3), (/0, 1, 2/))  ; zonal meridional-wind anomaly\n",
    "ehf = dim_avg_n(tstar * vstar, 3)  ; eddy heat flux\n",
    "copy_VarCoords(t(:, :, :, 0), ehf)\n",
    "ehf@long_name = \"eddy heat flux\"\n",
    "ehf@units = \"K*m/s\"\n",
    "o->ehf = ehf\n",
    "```\n",
    "\n",
    "Running `ncl fluxes.ncl` will show the following (will not work inside this notebook).\n",
    "```\n",
    "Variable: t\n",
    "Type: double\n",
    "Total Size: 6912000 bytes\n",
    "            864000 values\n",
    "Number of Dimensions: 4\n",
    "Dimensions and sizes:\t[time | 200] x [plev | 60] x [lat | 6] x [lon | 12]\n",
    "Coordinates: \n",
    "            time: [0.25..99.75]\n",
    "            plev: [8.44375..1004.806]\n",
    "            lat: [-75..75]\n",
    "            lon: [-165..165]\n",
    "Number Of Attributes: 2\n",
    "  long_name :\ttemperature\n",
    "  units :\tK\n",
    "\n",
    "Variable: v\n",
    "Type: double\n",
    "Total Size: 6912000 bytes\n",
    "            864000 values\n",
    "Number of Dimensions: 4\n",
    "Dimensions and sizes:\t[time | 200] x [plev | 60] x [lat | 6] x [lon | 12]\n",
    "Coordinates: \n",
    "            time: [0.25..99.75]\n",
    "            plev: [8.44375..1004.806]\n",
    "            lat: [-75..75]\n",
    "            lon: [-165..165]\n",
    "Number Of Attributes: 2\n",
    "  long_name :\tmeridional wind\n",
    "  units :\tm/s\n",
    "\n",
    "Variable: ehf\n",
    "Type: double\n",
    "Total Size: 576000 bytes\n",
    "            72000 values\n",
    "Number of Dimensions: 3\n",
    "Dimensions and sizes:\t[time | 200] x [plev | 60] x [lat | 6]\n",
    "Coordinates: \n",
    "            time: [0.25..99.75]\n",
    "            plev: [8.44375..1004.806]\n",
    "            lat: [-75..75]\n",
    "Number Of Attributes: 2\n",
    "  units :\tK*m/s\n",
    "  long_name :\teddy heat flux\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7426c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf fluxes_output {\n",
      "dimensions:\n",
      "\ttime = 200 ;\n",
      "\tplev = 60 ;\n",
      "\tlat = 18 ;\n",
      "variables:\n",
      "\tdouble ehf(time, plev, lat) ;\n",
      "\t\tehf:units = \"K*m/s\" ;\n",
      "\t\tehf:long_name = \"eddy heat flux\" ;\n",
      "\tfloat time(time) ;\n",
      "\t\ttime:standard_name = \"time\" ;\n",
      "\t\ttime:axis = \"T\" ;\n",
      "\t\ttime:units = \"days since 00-01-01 00:00:00\" ;\n",
      "\t\ttime:calendar = \"360_day\" ;\n",
      "\t\ttime:long_name = \"time\" ;\n",
      "\tfloat plev(plev) ;\n",
      "\t\tplev:standard_name = \"pressure level\" ;\n",
      "\t\tplev:axis = \"Z\" ;\n",
      "\t\tplev:units = \"hPa\" ;\n",
      "\t\tplev:long_name = \"pressure level\" ;\n",
      "\tfloat lat(lat) ;\n",
      "\t\tlat:standard_name = \"latitude\" ;\n",
      "\t\tlat:axis = \"Y\" ;\n",
      "\t\tlat:units = \"degN\" ;\n",
      "\t\tlat:long_name = \"latitude\" ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# rm data/fluxes_output.nc 2>/dev/null\n",
    "# ncl fluxes.ncl\n",
    "ncdump -h data/fluxes_output.nc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#ece260",
    "navigate_num": "#000000",
    "navigate_text": "#000000",
    "running_highlight": "#FF0000",
    "selected_highlight": "#fff968",
    "sidebar_border": "#ffffff",
    "wrapper_background": "#ffffff"
   },
   "moveMenuLeft": false,
   "nav_menu": {
    "height": "300px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "838px",
    "left": "0px",
    "right": "1431px",
    "top": "110px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
